# Custom `FeaturizedConvolution` Network ğŸ”¥ğŸ†


---


***Remarks:*** As of a survey with some classmates until September 10th, This is the `smallest` and `fastest` model in the Deep Learning class right now! ğŸ¥‡


---



1.   smaller than `AutoML` ensemble model params that stacked many models in many layers (e.g. WeightEnsembleL2/L3 from AutoGluon)

2.   obtain `81.25% accuracy`âœ… by containing only `176 parameters`! which is smaller than the professor model (neural network with 209params achieving 76% accuracy)
<img align="middle" width="900" src="https://github.com/Nardien/KALA/blob/master/images/concept_fig.png">

4. faster training time `(<30 seconds even when performing cross-validation)` even it utilize CPU as an accelerator âš¡

5. no need for ensembling of many trees that required many increased parameters ğŸŒ³

6. achieves `competitive performance` with gradient-boosting algorithm or some deep learning model (e.g. catboost79, professorModel76) â›¹

---
- Credits: This Architecture was designed by `Mr. Pavaris Ruangchutiphophan` inspired by an idea of 1-dimensional convolution on signal data
---
